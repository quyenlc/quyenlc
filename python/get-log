#!/usr/bin/python

import argparse
import sys
import boto3
import botocore
import os 
import logging
import re
import subprocess

from Infra import tar

parser = argparse.ArgumentParser(prog='get-log', description='Get log by date')
parser.add_argument('--debug', action='store_true', help='Enable debug mode')
parser.add_argument('--dry-run', action='store_true', help='Dry run mode')
parser.add_argument('-l', '--log', nargs=1, help="logfile. Default: %(prog)s.log", default=[parser.prog + ".log"])
parser.add_argument('--version', action='version', version='%(prog)s 1.0')

parser.add_argument('--bucket', nargs=1, help='Bucket name', required=True)
parser.add_argument('--date', nargs=1, help='Date of log file', required=True)
parser.add_argument('--out-dir', nargs=1, help='Directory to download data to')
args = vars(parser.parse_args(sys.argv[1:]))

# Config logger
if args['debug'] == True:
    logging.basicConfig(level=logging.DEBUG, format = ' %(asctime)s [%(levelname)s] : %(message)s', filename=args['log'][0])
else :
    logging.basicConfig(level=logging.INFO, format = ' %(asctime)s [%(levelname)s] : %(message)s', filename=args['log'][0])
logging.getLogger().addHandler(logging.StreamHandler())

logging.debug("ARGS: " + str(args))

#Validate working directoty
out_dir = args['date'][0]
if args['out_dir'] != None:
	out_dir = args['out_dir'][0]
if not args['dry_run']:
	if os.path.exists(out_dir):
		logging.error("Directory " + out_dir + " has been existed. Please remove it then try again")
	else:
		logging.info("Create working directory: "+ out_dir)
		os.makedirs(out_dir)
s3 = boto3.resource('s3')
bucket_name = args['bucket'][0]
bucket = s3.Bucket(bucket_name)


def getKeys():
	key_prefix = args['date'][0][:6] + r"/web:cotk_jp/"
	logging.debug("Key prefix: " + key_prefix)
	month_check = re.compile(key_prefix)
	date_check = re.compile(args['date'][0])
	keys = []
	for key in bucket.objects.all():
		if month_check.search(key.key) != None and date_check.search(key.key) != None:
			keys.append(key.key)
	return keys

def loadKey(key_name):
	logging.info("Loading key name " + key_name)
	file_name = "/".join(key_name.split("/")[3:])
	folder_name = key_name.split("/")[2]
	logging.debug("Folder name: " + folder_name + " | File name: " + file_name)
	if not os.path.exists(out_dir+"/"+folder_name):
		logging.info("Create sub working directory: "+ folder_name)
		os.makedirs(out_dir + "/" + folder_name)
	s3.Object(bucket_name, key_name).download_file(out_dir + "/" + folder_name + "/" + file_name)


try:
    s3.meta.client.head_bucket(Bucket=bucket_name)
except botocore.exceptions.ClientError as e:
    # If a client error is thrown, then check that it was a 404 error.
    # If it was a 404 error, then the bucket does not exist.
    error_code = int(e.response['Error']['Code'])
    if error_code == 404:
        logging.error("Bucket " + bucket_name + " does not exist or you don't have permission to access it")
        exit()

keys = getKeys()

if args['dry_run'] == True:
	logging.info("Dry run mode is enabled. Stop download process")
	exit()

for key in keys:
	loadKey(key)
if not args['dry_run']:
	tar(out_dir)


